{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RK_01_EarthCube_GeoEDF_Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author(s)\n",
    "List authors, their current affiliations,  up-to-date contact information, and ORCID if available. Add as many author lines as you need. \n",
    "\n",
    "- Author1 = {\"name\": \"Rajesh Kalyanam\", \"affiliation\": \"Purdue Research Computing\", \"email\": \"rkalyana@purdue.edu\", \"orcid\": \"0000-0002-7026-7419\"}\n",
    "- Author2 = {\"name\": \"Lan Zhao\", \"affiliation\": \"Purdue Research Computing\", \"email\": \"lanzhao@purdue.edu\"}\n",
    "- Author3 = {\"name\": \"Carol Song\", \"affiliation\": \"Purdue Research Computing\", \"email\": \"cxsong@purdue.edu\"}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "This notebook demonstrates **GeoEDF**, a new Python-based plug-and-play workflow framework for composing and executing end-to-end geospatial research workflows in a cyberinfrastructure environment. GeoEDF seeks to free researchers from the time-consuming data wrangling tasks and focus on their scientific research. \n",
    "\n",
    "## Technical contributions\n",
    "\n",
    "* **GeoEDF** (Geospatial **E**xtensible **D**ata **F**ramework)[<sup id=\"fn1-back\">1</sup>](#fn1) is a novel abstraction of geospatial workflows as a sequence of reusable data acquisition (_connector_) and processing (_processor_) steps.\n",
    "* A YAML-based workflow syntax for composing geospatial workflows out of data _connectors_ and data _processors_.\n",
    "* A Python-based **GeoEDF** workflow engine for planning and executing the YAML workflows on diverse compute resources.\n",
    "* A growing repository of community contributed connectors and processors that can be used in research workflows. \n",
    "\n",
    "## Methodology\n",
    "\n",
    "1. GeoEDF data connectors and processors are essentially Python classes that implement a standard interface. \n",
    "2. Connectors implement various data access protocols and assist in acquiring data from remote repositories (for e.g., NASA, USGS, etc.). Processors implement various domain agnostic and domain specific geospatial processing operations.\n",
    "3. Data connectors and processors are contributed as open-source to GitHub where a CI/CD (continuous integration/continuous deployment) pipeline packages them as Singularity containers and deploys them to a GeoEDF Singularity registry.\n",
    "4. Users can utilize any of these connectors or processors for their workflows or design and contribute their own.\n",
    "5. The GeoEDF workflow engine can be used standalone as in this Docker container example, or integrated into a science gateway. \n",
    "\n",
    "The GeoEDF workflow engine leverages the [Pegasus Workflow Management System](https://pegasus.isi.edu/) for workflow planning and execution on diverse compute resources (local machine, Condor pool, HPC, etc.). This container is based on the [Pegasus Workflow Development Environment](https://github.com/pegasus-isi/pegasus-workflow-development-environment). \n",
    "\n",
    "\n",
    "## Results\n",
    "\n",
    "This notebook demonstrates a GeoEDF hydrologic workflow that acquires data (in HDF format) from a NASA Distributed Active Archive Center (DAAC) and aggregates the data across a provided watershed region. This is often the first step before running a hydrologic model. \n",
    "\n",
    "![Workflow](files/img/research.png)\n",
    "\n",
    "In GeoEDF, this workflow combines a data connector (**NASAInput**) and processor (**HDFEOSShapefileMask**) as follows:\n",
    "\n",
    "![Workflow](files/img/mcd.png)\n",
    "\n",
    "The corresponding YAML GeoEDF workflow [file](./workflow/mcd15.yml) is as follows:\n",
    "\n",
    "```\n",
    "$1:\n",
    "  Input:\n",
    "    NASAInput:\n",
    "      url: https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/%{filename}\n",
    "      user: rkalyana\n",
    "      password:\n",
    "  Filter:\n",
    "    filename:\n",
    "      PathFilter:\n",
    "        pattern: '%{dtstring}/MCD15A3H.*.h09v07*.hdf'\n",
    "    dtstring:\n",
    "      DateTimeFilter:\n",
    "        pattern: '%Y.%m.%d'\n",
    "        start: 07/16/2002\n",
    "$2:\n",
    "  HDFEOSShapefileMask:\n",
    "    hdffile: $1\n",
    "    shapefile: /home/earthcube/geoedf/files/watershed/subs1_projected_171936.shp\n",
    "    datasets: [Lai]\n",
    "```\n",
    "\n",
    "**Note:** \n",
    "\n",
    "1. A GeoEDF workflow combines _instances_ of connector or processor classes. The YAML syntax enables the user to specify bindings for the class arguments for the connector or processor (e.g., url, user, shapefile, etc.).\n",
    "2. Filters enhance the generality of connectors. In this specific case, HDF data for a specific time period can be acquired by modifying the _DateTimeFilter_ appropriately. Similarly, wildcards ('*') in the _PathFilter_ enable search across all the files hosted in that directory on the repository.\n",
    "3. Filters essentially provide one or more binding values for variables referenced in other connectors or filters. For example, the _filename_ variable in the _NASAInput_ connector is bound by the _PathFilter_; and the _dtstring_ variable in _PathFilter_ is bound by the _DateTimeFilter_.\n",
    "3. Numeric indices are used to denote the workflow step and establish output-input linkages between steps. \n",
    "4. Fields left blank (for e.g., _password_) are instantiated at workflow execution time by prompting the user to specify a value.\n",
    "\n",
    "## Funding\n",
    "\n",
    "- Award1 = {\"agency\": \"NSF\", \"award_code\": \"1835833\", \"award_URL\": \"https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835822\"}\n",
    "\n",
    "## Keywords\n",
    "\n",
    "keywords=[\"workflow\", \"geospatial\", \"Pegasus\", \"containers\", \"cyberinfrastructure\"]\n",
    "\n",
    "## Citation\n",
    "\n",
    "Kalyanam, R., Zhao, L., Song, C., GeoEDF Demo Notebook, EarthCube 2021 Annual Conference.\n",
    "\n",
    "## Suggested next steps\n",
    "\n",
    "* Further documentation on GeoEDF can be found at [GeoEDF Documentation] (https://geoedf.readthedocs.io/en/latest/)\n",
    "* GeoEDF is coming soon to the Jupyter tool environment on the [MyGeoHub Science Gateway] (https://mygeohub.org). Users will be able to create and execute workflows, and manage and publish the workflow results on this gateway. \n",
    "* Current connector and processor definitions can be found in the [GeoEDF GitHub Repositories](https://github.com/geoedf). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## Library import\n",
    "\n",
    "**GeoEDFWorkflow** is the primary class that will be used to instantiate and execute the workflow above.\n",
    "\n",
    "GeoEDF uses the _sregistry_ Singularity client library to interact with the GeoEDF Singularity registry. In order to turn off the informational messages from this library, we first set the _MESSAGELEVEL_ environment variable to _QUIET_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['MESSAGELEVEL'] = 'QUIET'\n",
    "\n",
    "from geoedfengine.GeoEDFWorkflow import GeoEDFWorkflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow Instantiation\n",
    "\n",
    "A new workflow object is created by instantiating the _GeoEDFWorkflow_ class with the workflow YML file path.\n",
    "\n",
    "**Note:**\n",
    "\n",
    "1. At this point, the GeoEDF engine will validate the workflow file for proper syntax (ensuring no cyclic dependencies, all variables are bound by filters, etc.). \n",
    "2. The user will be prompted to enter values for any variables that have been left blank (for e.g., _password_).\n",
    "3. Enter the value _NASAservice123_ when prompted for the password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = GeoEDFWorkflow('/home/earthcube/geoedf/workflow/mcd15.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Workflow Execution\n",
    "\n",
    "_GeoEDFWorkflow_ provides a method for executing workflows. In this case, we execute workflows locally on a Condor pool running in the container. Other execution sites can be configured in the Pegasus site catalog and provided as input during workflow instantiation. We do not include this feature in this demonstration due to its setup complexity.\n",
    "\n",
    "**Note:**\n",
    "\n",
    "1. Workflow execution is synchronous; on execution, a progress bar (0 - 100%) will be displayed.\n",
    "2. Workflow may take a while to run based on the resources available to your local Docker engine. \n",
    "2. Workflow may report a _Failure_ from time to time since it is reaching out to an external NASA DAAC. If this happens, please check to see if https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006 is reachable in your browser and then repeat the steps (a) instantiate the workflow, (b) execute the workflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "If the workflow succeeded, the output is an ESRI Shapefile which can be found in the output directory reported by the execute step above. However, there is no easy way to verify or visualize the result. There are Python mapping libraries (e.g. Folium or ipyLeaflet) that work with geospatial files, but require vector data to be in the GeoJSON format.\n",
    "\n",
    "As a next step, we demonstrate how a new processor can be developed for converting a shapefile into a GeoJSON file and appended as a third step to the above workflow. This demonstration can be found in the **_RK_02_EarthCube_GeoEDF_Demo_** notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[<sup id=\"fn1\">1</sup>](#fn1-back) Kalyanam, R., Zhao, L., Song, X.C., Merwade, V., Jin, J., Baldos, U. and Smith, J., 2020. Geoedf: An extensible geospatial data framework for fair science. In Practice and Experience in Advanced Research Computing (pp. 207-214)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "248.182px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
