{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RK_02_EarthCube_GeoEDF_Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author(s)\n",
    "List authors, their current affiliations,  up-to-date contact information, and ORCID if available. Add as many author lines as you need. \n",
    "\n",
    "- Author1 = {\"name\": \"Rajesh Kalyanam\", \"affiliation\": \"Purdue Research Computing\", \"email\": \"rkalyana@purdue.edu\", \"orcid\": \"0000-0002-7026-7419\"}\n",
    "- Author2 = {\"name\": \"Lan Zhao\", \"affiliation\": \"Purdue Research Computing\", \"email\": \"lanzhao@purdue.edu\"}\n",
    "- Author3 = {\"name\": \"Carol Song\", \"affiliation\": \"Purdue Research Computing\", \"email\": \"cxsong@purdue.edu\"}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "This notebook demonstrates how a new GeoEDF processor can be developed and used in a workflow. It is primarily intended to demonstrate the extensibility and flexibility of the GeoEDF framework.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "1. A _Shapefile2GeoJSON_ processor has been included in the container. This is a domain agnostic processor that simply takes an ESRI Shapefile's containing directory as input and produces a GeoJSON file output.\n",
    "2. This notebook demonstrates the utilities available to package the processor so that it can be used in a workflow.\n",
    "3. While the new processor will be packaged (as a Singularity container) and saved locally in this container for this demonstration, in a production environment the GeoEDF GitHub CI/CD pipeline is used to package and push a newly contributed (via pull requests) processor to the GeoEDF Singularity registry.\n",
    "\n",
    "## Results\n",
    "\n",
    "The revised three step workflow that will be demonstrated in this notebook is as follows:\n",
    "\n",
    "![Workflow](files/img/mcd-viz.png)\n",
    "\n",
    "The corresponding YAML GeoEDF workflow [file](./workflow/mcd15-viz.yml) is as follows:\n",
    "\n",
    "```\n",
    "$1:\n",
    "  Input:\n",
    "    NASAInput:\n",
    "      url: https://e4ftl01.cr.usgs.gov/MOTA/MCD15A3H.006/2002.07.16/MCD15A3H.*.h09v07*.hdf\n",
    "      user: rkalyana\n",
    "      password:\n",
    "$2:\n",
    "  HDFEOSShapefileMask:\n",
    "    hdffile: $1\n",
    "    shapefile: /home/earthcube/geoedf/files/watershed/subs1_projected_171936.shp\n",
    "    datasets: [Lai]\n",
    "$3:\n",
    "  Shapefile2GeoJSON:\n",
    "    inputdir: dir($2)\n",
    "```\n",
    "\n",
    "The Python package definition and implementation of the _Shapefile2GeoJSON_ processor can be found [here](./files/shapefile2geojson).\n",
    "\n",
    "## Funding\n",
    "\n",
    "- Award1 = {\"agency\": \"NSF\", \"award_code\": \"1835833\", \"award_URL\": \"https://www.nsf.gov/awardsearch/showAward?AWD_ID=1835822\"}\n",
    "\n",
    "## Keywords\n",
    "\n",
    "keywords=[\"workflow\", \"geospatial\", \"Pegasus\", \"containers\", \"cyberinfrastructure\"]\n",
    "\n",
    "## Citation\n",
    "\n",
    "Kalyanam, R., Zhao, L., Song, C., GeoEDF Custom Processor Demo Notebook, EarthCube 2021 Annual Conference.\n",
    "\n",
    "## Suggested next steps\n",
    "\n",
    "* Further documentation on GeoEDF connector and processor templates can be found at [GeoEDF Documentation](https://geoedf.readthedocs.io/en/latest/).\n",
    "* Current connector and processor definitions can be found in the [GeoEDF Connector Repository](https://github.com/geoedf/connectors) and [GeoEDF Processor Repository](https://github.com/geoedf/processors). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processor Development\n",
    "\n",
    "Typically, a user would develop a new connector or processor following the template of existing processors or connectors in the GeoEDF repository. We have included an example implementation of the _Shapefile2GeoJSON_ processor [here](./files/shapefile2geojson). Apart from the typical Python library classes, there is also a _recipe.hpccm_ file that is used to create the Singularity definition file and (subsequently) container. \n",
    "\n",
    "_recipe.hpccm_ utilizes the [NVIDIA HPC Container Maker](https://github.com/NVIDIA/hpc-container-maker) utility to simplify the definition of Singularity and Docker definition files. This allows contributors to quickly specify the OS and Python library dependencies for a connector or processor without having to be familiar with the specifics of the Singularity definition syntax. The _hpccm_ utility is used to create a Singularity definition file from this recipe file.\n",
    "\n",
    "The _build-local-image_ [script](./files/build-local-image.sh) executes the following steps to package the processor into a Singularity container that can then be used in the workflow:\n",
    "\n",
    "1. Create a Singularity definition file from the recipe.hpccm file.\n",
    "2. Build a Singularity container from the definition file.\n",
    "3. Copy the resulting Singularity container image to a local /images directory where GeoEDF can find additional connectors and processors during development (in addition to the GeoEDF Singularity registry server).\n",
    "\n",
    "We will execute this script next to create the container for the _Shapefile2GeoJSON_ processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./files/build-local-image.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "As noted, the ability to build and test local connector and processor Singularity containers in workflows greatly simplifies the development process. Moreover, a mix of existing and new connectors and processors can be used since the GeoEDF workflow engine can use both containers hosted on the GeoEDF Singularity registry and locally built containers. \n",
    "\n",
    "Once a user is satisfied with their developed container, they can use a GitHub pull request to contribute their new connector or processor to the corresponding GeoEDF repositories. The GeoEDF CI/CD pipeline essentially repeats the same steps as the _build-local-image_ script, except for pushing the Singularity container image to the GeoEDF registry at the end.\n",
    "\n",
    "Next, we will use this new processor in our prior workflow to help produce a GeoJSON file that can be visualized in this same Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## Library import\n",
    "\n",
    "As before, the **GeoEDFWorkflow** class will be imported and used to execute this new workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['MESSAGELEVEL'] = 'QUIET'\n",
    "\n",
    "from geoedfengine.GeoEDFWorkflow import GeoEDFWorkflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow Instantiation\n",
    "\n",
    "A new workflow object for the three step workflow is created by instantiating the _GeoEDFWorkflow_ class with the new workflow YML file path.\n",
    "\n",
    "**Note:**\n",
    "\n",
    "1. Enter the value _NASAservice123_ when prompted for the password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = GeoEDFWorkflow('/home/earthcube/geoedf/workflow/mcd15-viz.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Workflow Execution\n",
    "\n",
    "As before, we use the _execute()_ method to execute this instantiated workflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports\n",
    "\n",
    "We will first import Python libraries necessary for reading in the GeoJSON output file and then visualizing it on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import \n",
    "\n",
    "First we import the GeoJSON file from the workflow's output directory and create the necessary GeoPandas _DataFrame_ for visualization using the Folium library.\n",
    "\n",
    "*Be sure to fill in the output directory reported by execute() above as the value for the **output_dir** variable below*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = ''\n",
    "geojson_path = '%s/MCD15A3H.A2002197.h09v07.006.2015149103156.hdf.json' % output_dir\n",
    "geo_df = gpd.GeoDataFrame.from_file(geojson_path)\n",
    "field_name = 'Lai_500m'\n",
    "mcd_df = geo_df.loc[:,[field_name,'geometry']]\n",
    "mcd_df['id'] = mcd_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Finally, we visualize the GeoJSON data as a color coded map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_map = folium.Map(location=[40,-86],zoom_start=7)\n",
    "\n",
    "test_map.choropleth(geo_data=mcd_df.to_json(),\n",
    "                    data=mcd_df,\n",
    "                    columns=['id',field_name],\n",
    "                    key_on='feature.properties.{}'.format('id'),\n",
    "                    legend_name = field_name,\n",
    "                    fill_color='YlOrRd',\n",
    "                    fill_opacity=0.5,\n",
    "                    line_weight=2)\n",
    "test_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "If the workflow succeeded, the output is a GeoJSON file that can be visualized inline on Jupyter notebooks using popular map visualization libraries. \n",
    "\n",
    "While this may be a contrived example, it demonstrates how a generic GeoEDF processor developed for one specific workflow can find use across various workflows and provide a useful tool for other researchers to develop their own end-to-end workflows in other domains. \n",
    "\n",
    "Previously, researchers would have had to download the resulting Shapefile after the second step to their desktop machine and visualize it on a desktop GIS tool such as QGIS. GeoEDF seeks to facilitate FAIR science by enabling researchers to conduct their end-to-end workflows entirely in a science gateway environment. Specifically, both workflow outputs and the workflow YAML file can be published with appropriate metadata to enable workflow reproducibility and validation by other researchers in the same gateway environments.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "248.182px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
